Certified Kubernetes Administrator course - NOTES

CLUSTER ARHITECTURE:
KUBERNETIC CLUSTER 
-a set of NODES physical/virtual on premises/on cloud that hosts applications in the form of a container
-contains WORKER NODES and a MASTER NODE(mamage worker nodes using control plane components)
ON MASTER we have: 
-ETCD CLUSTER- a database that stores information in a key/value format 
-KUBE-SCHEDULER - identifies the right node to place a container on 
-KUBE CONTROLLER - Node Controller, Replication Controller 
-KUBE-APISERVER - primary management component of kubernetics 
ON WORKER nodes we have:
-KUBELET - an agent that runs on each node on a cluster -listens from instructions from apiserver 
-KUPE-PROXY that helps enabling communication between services in the cluster 

ETCD Cluster - stores informations about Nodes, pods, configs, secrets, accounts, roles, bindings 
  -is installed on master node
  -listens on port 2379 

KUBE-API SERVER - the only component that interact directly with the ETCD Cluster
  -is responsible for authenticating and validating requests, retriving data, updating the ETCD, 
interacting with Scheduler and Kubelet(they are using the Kube-api to perform updates in the cluster)

KUBE CONTROLLER - a process that continously monitors the status of the cluster 
- Node Controller - checks the health of the nodes 
- Replication Controllers - monitors the status of replica sets- assures the desired number of pods 
-all controllers are installed in Kube-Controller-Manager 

-KUBE-SCHEDULER - decides with pods goes on which node (only decides, not place it) 
-KUBELET - register Node, create PODs, monitors Node and PODs (kubeadmn dos not automatically deploys kubelet)
-KUPE-PROXY - is a process that runs on each node in cluster 
-looks for new servicess, and every time a new service is created it creates the rulles to fwd traffic to pods
-uses ip-table rulles 

pod_def.yml
apiVersion: v1
kind: Pod
metadata:
  name: myapp-pod
  type: front-end
spec:
  containers:
    - name: nginx-controller
	  image: nginx

Commands:
# Generate POD Manifest YAML file (-o yaml)
kubectl run nginx --image=nginx --dry-run=client -o yaml
kubectl create -f pod-definition.yml
kubectl create -f pod-definition.yml --namespace=dev # create a pod in a different namespace than default
kubectl get pods
kubectl get pods --namespace=dev 
#copy the yaml of POD webapp to a  my-new-pod.yaml 
kubectl get pod webapp -o yaml > my-new-pod.yaml 

#monitors the status of the pods
kubectl get pods --watch 

controlplane ~ ➜  kubectl get pods -o wide
NAME    READY   STATUS    RESTARTS   AGE   IP           NODE     NOMINATED NODE   READINESS GATES
nginx   1/1     Running   0          13s   172.17.1.2   node01   <none>           <none>
kubectl describe pod myapp-pod

Example - Create a new pod with the name redis and the image redis123.
controlplane ~ ➜  kubectl run redis --image=redis123 --dry-run=client -o yaml > redis-definition.yaml
controlplane ~ ➜  kubectl create -f redis-definition.yaml
pod/redis created

# Create a pod named webapp-green, image set to kodecloud/webapp-color and command line arguments --color=green 
kubectl run webapp-green --image=kodecloud/webapp-color -- --color green 

ReplicationController:
kubectl create -f rc-definition.yml
kubectl get replicationController

ReplicaSets:
controlplane ~ ✖ cat replicaset-definition-1.yaml 
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: replicaset-1
spec:
  replicas: 2
  selector:
    matchLabels:
      tier: frontend
  template:
    metadata:
      labels:
        tier: frontend
    spec:
      containers:
      - name: nginx
        image: nginx

kubectl create -f replicaset-definition.yml
kubectl get replicaset
kubectl replace -f replicaset-definition.yml #if we want to update the nr of replicas
kubectl scale --replicas=6 replicaset-definition.yml # se poate face si cu scale dar in yaml raman tot 3 setate
kubectl scale --replicas=6 replicaset myapp-replicaset 
kubectl edit  replicasets new-replica-set  # edit something in the replicaset def- delete pods to apply changes

DEPLOYMENTS - provides the capabilities to perform upgrades seemlessly using rolling updates, undo changes

apiVersion: apps/v1
kind: Deployment
metadata:
  name: httpd-frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      name: httpd-frontend-pod
  template:
    metadata:
      labels:
        name: httpd-frontend-pod
    spec:
      containers:
      - name: httpd-frontend
        image: httpd:2.4-alpine

Commands:
#Generate Deployment YAML file (-o yaml)
kubectl create deployment --image=nginx nginx --dry-run=client -o yaml
kubectl create deployment --image=nginx nginx --dry-run=client -o yaml > nginx-deployment.yaml
kubectl create -f deployment-definition.yaml
kubectl create deployment --image=nginx nginx --replicas=4 --dry-run=client -o yaml > nginx-deployment.yaml
kubectl get deployments
kubectl get replicaset
kubectl get pods
kubectl get all- vezi toate cele 3 de sus 

SERVICES - enables communications between various components of an application - enables connectivity between the group of PODS
- NODE PORT SERVICE 
   - an object that listens to a port of a node and forwards the request to a port of the application 
   - range 30000-32767
- CLUSTERIP 
- LOADBALANCER 

service-definition.yml
apiVersion: v1
kind: Service
metadata:
  name: myapp-service
spec:
  type: NodePort # ClusterIP/LoadBalancer
  ports:
    - targetPort: 80
      port: 80
	  nodePort: 3008
  selector:
    app: myapp
	type: front-end
Commands:
kubectl create -f service-definition.yml
kubectl get services 
kubectl describe services kubernetes_service_name

NAMESPACES - separates resources in cluster 
kubectl get namespaces
#create a pod in a different namespace than default
kubectl create -f pod-definition.yml --namespace=dev

#create a new namespace called dev-ns
kubectl create namespace dev-ns

#get pods from the dev namespace
kubectl get pods --namespace=dev 

#switch to dev namespace
kubectl config set-context $(kubectl config current-context) --namespace=dev 
kubectl get pods --all-namespaces 

IMPERATIVE/DECLARATIVE Commands:

Imperative - kubectl create/get etc
Declarative - kubectl apply -f nginx.yaml

POD
#Create an NGINX Pod
kubectl run nginx --image=nginx
#Generate POD Manifest YAML file (-o yaml). Don't create it(--dry-run)
kubectl run nginx --image=nginx --dry-run=client -o yaml
# add a label
kubectl run redis --image=redis:alpine  --labels="tier=db" 

Deployment
#Create a deployment
kubectl create deployment --image=nginx nginx
#Generate Deployment YAML file (-o yaml). Don't create it(--dry-run)
kubectl create deployment --image=nginx nginx --dry-run=client -o yaml
#Generate Deployment with 4 Replicas
kubectl create deployment nginx --image=nginx --replicas=4
kubectl scale deployment nginx --replicas=4

#Another way to do this is to save the YAML definition to a file and modify
kubectl create deployment nginx --image=nginx --dry-run=client -o yaml > nginx-deployment.yaml
#You can then update the YAML file with the replicas or any other field before creating the deployment.

Service
#Create a Service named redis-service of type ClusterIP to expose pod redis on port 6379
kubectl expose pod redis --port=6379 --name redis-service --dry-run=client -o yaml
#(This will automatically use the pod's labels as selectors) Or
kubectl create service clusterip redis --tcp=6379:6379 --dry-run=client -o yaml 
#(This will not use the pods labels as selectors,instead it will assume selectors as app=redis. 
#You cannot pass in selectors as an option. So it does not work very well if your pod has a different label set. 
#So generate the file and modify the selectors before creating the service)
#Create a Service named nginx of type NodePort to expose pod nginx's port 80 on port 30080 on the nodes:
kubectl expose pod nginx --type=NodePort --port=80 --name=nginx-service --dry-run=client -o yaml
#(This will automatically use the pod's labels as selectors, but you cannot specify the node port. 
#You have to generate a definition file and then add the node port in manually before creating the
#service with the pod.) Or
kubectl create service nodeport nginx --tcp=80:80 --node-port=30080 --dry-run=client -o yaml

controlplane ~ ➜  kubectl run httpd --image=httpd:alpine --port=80 --expose
service/httpd created
pod/httpd created

SCHEDULING:
Manual scheduling - manually assign PODs to Nodes 
- set nodeName in pod.yaml at POD creation 
- bind the POD that is alleardy created using a pod-bind-def.yaml(needs to be transform in json format) - set name in target field and bind it
curl --header "Content-Type:application/json" --request POST --data '{"apiVersion":"v1", "kind":"Binding"...} http://$SERVER/api/v1/namespace/default/pods/$PODNAME/binding/

#force - deletes and recreates a pod/replicaset/etc after making changes in yaml
kubectl replace --force -f ngnix.yaml 
kubectl replace --force -f replicaset-definition-1.yaml 

LABELS AND SELECTORS:
Selector: specify selector in pod.yaml definition
kubectl get pods --selector app=Ap1
kubectl get all --selector env=prod
#count pods that are in Ap1, prod and in finace 
kubectl get pods --selector app=Ap1, env=prod, bu=finace wc -l 

TAINTS AND TOLERANCE- says to Pods not to go to a certain Node but go to Node with certains tolerantions 
Tolerance is added in pod.yaml def  using tolerations 
kubectl taint nodes node-name key=value:taint-effect
kubectl taint nodes node1 app=blue:NoSchedule
kubectl describe node kubemaster | grep Taint 
kubectl taint nodes node01 spray=mortein:NoSchedule

# Untain using - at the end:
kubectl taint nodes controlplane node-role.kubernetes.io/control-plane:NoSchedule-

NODES SELECTORS - used for setting limitations on PODS to only run on specific Nodes 
-field nodeSelector in pod.yaml - for PODs Medium and Large 
kubectl label nodes <node-name> <label-key>=<label-value>
kubectl label nodes node-1 size=Large

NODE AFFINITY: ensures that PODs run on specific Nodes 
-field affinity/NodeAffinity in pod.yaml 

RESOURCE LIMITS:
-field resources in pod.yaml
-field limits in pod.yaml
LimitRanges-object to limit request and limits- for cpu and memory - affects only PODs that will be created(not the existing ones)

RESOURCE QUOTAS- at namespace level - 
- a namespace object created to set part limits of resources 

DAEMON SETS - assures that one copy of a POD is always present on the cluster- similar to replicaset 
kind: DaemonSet
kubectl create -f daemon-set-definition.yaml
kubectl get daemonsets

#get daemonsets in all namespaces
kubectl get daemonsets.apps --all 

STATIC PODS - are created by the Kubelet -control-plane
/etc/kubernetes/manifests
docker ps 
#Create a static pod named static-busybox that uses the busybox image and the command sleep 1000
kubectl run --restart=Never --image=busybox static-busybox --dry-run=client -o yaml --command -- sleep 1000 > /etc/kubernetes/manifests/static-busybox.yaml

#Multiple SCHEDULERS
kubectl create configmap my-scheduler-config --from-file=/root/my-scheduler-config.yaml -n kube-system 
kubectl get configmap my-scheduler-config -n kube-system 

MONITOR CLUSTER COMPONENTS:
METRICS SERVER 
#install metric-server on minikube
minikube addons enable metrics-server
#install metric-server
git clone https://github.com/kubernetes-incubator/metric-server.github
kubectl create -f deploy/1.8+/
#see metrics
kubectl top node
kubectl top pods 

LOGS:
kubectl logs -f pod_name 
kubectl logs -f pod_name container_name

ROLLING UPDATES AND ROLLBACKS 
#check the rollout status 
kubectl rollout status deployment/myapp-deployment 
#check the history of the rollout versions 
kubectl rollout history deployment/myapp-deployment 

DEPLOYMENT STRATEGY:
RECREATE - destroy the pods and recreate- the app will have a down time
ROLLING UPDATE - destroy and recreate one by one  - the default deployment strategy 
-The strategy type can be seen in kubectl describe deployment my-deploy under StrategyType field
Rollback:
kubectl  rollout undo deployment/myapp-deployment 
kubectl get replicaset 
CMDS:
CREATE - kubectl create -f deployment-deployment-definition.yml
CREATE&RECORD - kubectl create -f deployment-deployment-definition.yml --record
-> se vede in Annotations
GET    - kubectl get deployment
UPDATE - kubectl apply -f deployment-definition.yml
       - kubectl set image deployment/myapp-deployment \nginx-container=nginx:1.9.1
STATUS - kubectl rollout status deployment/myapp-deployment
       - kubectl rollout history deployment/myapp-deployment
ROLLBACK kubectl rollout undo deployment myapp-deployment
